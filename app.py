# ğŸš€ ë‰´ìŠ¤íŒ©í† ë¦¬ - AI ê¸°ë°˜ ê¸°ì‚¬ ë¶„ì„ í”Œë«í¼ (konlpy ë²„ì „)
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import re
import os
import time
import hashlib
from pathlib import Path
import requests
import pickle
import json
from collections import Counter, defaultdict
import subprocess
import sys
import calendar

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ konlpy Okt ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from konlpy.tag import Okt
okt = Okt()

# ìë™ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í•¨ìˆ˜
def install_package(package):
    """íŒ¨í‚¤ì§€ ìë™ ì„¤ì¹˜"""
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
        return True
    except subprocess.CalledProcessError:
        return False

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
def safe_import():
    """ê°œì„ ëœ ì•ˆì „í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import"""
    global TfidfVectorizer, cosine_similarity
    # í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
    try:
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.metrics.pairwise import cosine_similarity
        st.success("âœ… ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ")
    except ImportError:
        st.warning("âš ï¸ scikit-learnì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        TfidfVectorizer = None
        cosine_similarity = None

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì´ˆê¸°í™”
safe_import()

# êµ¬ê¸€ ì‹œíŠ¸ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
try:
    from google_sheets_utils_deploy import (
        load_data_from_google_sheets, preprocess_dataframe,
        test_connection, get_google_sheets_client, get_connection_status
    )
    SHEETS_UTILS_AVAILABLE = True
except ImportError:
    SHEETS_UTILS_AVAILABLE = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸš€ ë‰´ìŠ¤íŒ©í† ë¦¬",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì „ì—­ ì„¤ì •
PERPLEXITY_API_KEY = st.secrets["PERPLEXITY_API_KEY"]
APP_PASSWORD = st.secrets["APP_PASSWORD"]

# ìºì‹œ ì„¤ì •
CACHE_DIR = Path("cache")
CACHE_DIR.mkdir(exist_ok=True)
DATA_CACHE_DIR = CACHE_DIR / "data"
DATA_CACHE_DIR.mkdir(exist_ok=True)
ANALYSIS_CACHE_DIR = CACHE_DIR / "analysis"
ANALYSIS_CACHE_DIR.mkdir(exist_ok=True)
API_CACHE_DIR = CACHE_DIR / "api_calls"
API_CACHE_DIR.mkdir(exist_ok=True)

# ì–´ë‘ìš´ í…Œë§ˆ CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .reportview-container {
        background: linear-gradient(90deg, #0f0f0f 0%, #1a1a1a 100%);
        color: #ffffff;
    }
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    .stButton > button {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 20px;
        padding: 0.5rem 1rem;
        font-weight: bold;
        transition: all 0.3s ease;
    }
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.3);
    }
    .metric-card {
        background: rgba(255,255,255,0.1);
        padding: 1rem;
        border-radius: 10px;
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255,255,255,0.2);
    }
    .insight-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        color: white;
        box-shadow: 0 4px 15px rgba(0,0,0,0.3);
    }
    .planning-item {
        background: rgba(255,255,255,0.05);
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #667eea;
    }
</style>
""", unsafe_allow_html=True)

# ================================
# ìºì‹± ì‹œìŠ¤í…œ
# ================================
def get_cache_key(data_type, industry, date_str=None):
    """ìºì‹œ í‚¤ ìƒì„±"""
    if date_str is None:
        date_str = datetime.now().strftime("%Y-%m-%d")
    key_string = f"{data_type}_{industry}_{date_str}"
    return hashlib.md5(key_string.encode()).hexdigest()

def save_to_cache(cache_type, key, data):
    """ìºì‹œì— ë°ì´í„° ì €ì¥"""
    try:
        if cache_type == "data":
            cache_file = DATA_CACHE_DIR / f"{key}.pkl"
        elif cache_type == "analysis":
            cache_file = ANALYSIS_CACHE_DIR / f"{key}.pkl"
        else:
            cache_file = API_CACHE_DIR / f"{key}.pkl"
        
        cache_data = {
            'data': data,
            'timestamp': time.time(),
            'date': datetime.now().strftime("%Y-%m-%d")
        }
        
        with open(cache_file, 'wb') as f:
            pickle.dump(cache_data, f)
        return True
    except Exception as e:
        st.error(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False

def load_from_cache(cache_type, key, max_age_hours=24):
    """ìºì‹œì—ì„œ ë°ì´í„° ë¡œë“œ"""
    try:
        if cache_type == "data":
            cache_file = DATA_CACHE_DIR / f"{key}.pkl"
        elif cache_type == "analysis":
            cache_file = ANALYSIS_CACHE_DIR / f"{key}.pkl"
        else:
            cache_file = API_CACHE_DIR / f"{key}.pkl"
        
        if not cache_file.exists():
            return None
        
        with open(cache_file, 'rb') as f:
            cache_data = pickle.load(f)
        
        # ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬
        cache_age = time.time() - cache_data['timestamp']
        if cache_age > max_age_hours * 3600:
            return None
        
        return cache_data['data']
    except:
        return None

# ================================
# API í˜¸ì¶œ
# ================================
def call_perplexity_api_cached(prompt, model="sonar-pro", max_age_hours=24):
    """ìºì‹±ëœ Perplexity API í˜¸ì¶œ"""
    try:
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = hashlib.md5(f"{prompt}_{model}".encode()).hexdigest()
        
        # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
        cached_result = load_from_cache("api", cache_key, max_age_hours)
        if cached_result:
            st.info("ğŸ”„ ìºì‹œì—ì„œ AI ë¶„ì„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
            return cached_result
        
        # API í˜¸ì¶œ
        headers = {
            "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": model,
            "messages": [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ê¸°ì‚¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ íŠ¸ë Œë“œì™€ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.3,
            "max_tokens": 1000
        }
        
        response = requests.post(
            "https://api.perplexity.ai/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            api_result = result["choices"][0]["message"]["content"]
            
            # ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥
            save_to_cache("api", cache_key, api_result)
            st.success("ğŸ†• ìƒˆë¡œìš´ AI ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
            return api_result
        else:
            st.error(f"API ì˜¤ë¥˜: {response.status_code}")
            return None
            
    except Exception as e:
        st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        return None

# ================================
# ğŸ”§ NEW UTILS (ìƒˆë¡œìš´ ê¸°ëŠ¥ í•¨ìˆ˜ë“¤)
# ================================
def compile_articles_text(articles, max_each=3):
    """ìœ ì‚¬ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ â†’ Promptìš© í…ìŠ¤íŠ¸ ë¬¸ìì—´"""
    texts = []
    for art in articles[:max_each]:
        title = art.get("ì œëª©", "")
        body = art.get("ì£¼ìš”ë‚´ìš©", "")
        if pd.notna(title):
            texts.append(f"ì œëª©: {title}\në‚´ìš©: {str(body)[:300]}")
    return "\n".join(texts)

def generate_monthly_ai_plans(insight_dict, df, industry="ì „ì²´"):
    """
    ì£¼ì°¨ë³„ í•µì‹¬ë¬¸ì¥ + ìœ ì‚¬ ê¸°ì‚¬ë“¤ì„ ë¬¶ì–´ Perplexity APIë¡œ 'AI ì¶”ì²œ ê¸°íš ì•„ì´í…œ' ìƒì„±
    """
    if not insight_dict or df.empty:
        return "ë°ì´í„°ê°€ ë¶€ì¡±í•´ ê¸°íš ì•„ì´í…œì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    plan_source_blocks = []
    for week, sentence in insight_dict.get("weekly_insights", {}).items():
        if not sentence:
            continue
        
        sims = find_similar_articles_to_insight(df, sentence, 7)
        sim_text = compile_articles_text([s["article"] for s in sims])
        
        plan_source_blocks.append(
            f"[{week}] í•µì‹¬ë¬¸ì¥: {sentence}\nê´€ë ¨ ê¸°ì‚¬:\n{sim_text}"
        )
    
    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ ì£¼ìš” ì¼ê°„ì§€ì˜ {industry if industry!='ì „ì²´' else ''} ë‹´ë‹¹ ë¶€ì¥ì…ë‹ˆë‹¤.
    ì•„ë˜ ì£¼ì°¨ë³„ í•µì‹¬ íŠ¸ë Œë“œì™€ ê´€ë ¨ ê¸°ì‚¬ë“¤ì„ ë¶„ì„í•´ ë‹¤ìŒ ë‹¬ ì·¨ì¬ ë°©í–¥ì„ ì œì‹œí•  'AI ì¶”ì²œ ê¸°íš ì•„ì´í…œ' 5ê±´ì„ ì‘ì„±í•˜ì„¸ìš”.
    
    [ìš”ì²­ í˜•ì‹]
    ì œì‹œ ë¬¸ì¥(ê¸°ì‚¬ ì œëª© í›„ë³´) - í•œ ì¤„ ì´ìœ 
    
    [ë¶„ì„ ëŒ€ìƒ ë°ì´í„°]
    {os.linesep.join(plan_source_blocks[:3])}
    """
    
    return call_perplexity_api_cached(prompt, max_age_hours=6)

def generate_custom_topic_brief(df, industry, topic, weight_threshold=0.45):
    """
    ì—…ê³„+ì£¼ì œ ê´€ë ¨ ê¸°ì‚¬ ì¶”ì¶œ í›„ Perplexity APIë¡œ ê³ ê¸‰ ë¸Œë¦¬í•‘ ìƒì„±
    """
    if df.empty or not topic:
        return None
    
    # ì—…ê³„ í•„í„°
    pool = df if industry == "ì „ì²´" else df[df["ì—…ê³„"] == industry]
    if pool.empty:
        return None
    
    # ìœ ì‚¬ë„ ê³„ì‚°
    pool = pool.copy()
    pool["combined_text"] = pool["ì œëª©"].fillna("") + " " + pool["ì£¼ìš”ë‚´ìš©"].fillna("")
    
    if not TfidfVectorizer or not cosine_similarity:
        return "TF-IDF ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    vec = TfidfVectorizer(max_features=1500)
    try:
        mat = vec.fit_transform(pool["combined_text"].tolist() + [topic])
        sims = cosine_similarity(mat[-1:], mat[:-1]).flatten()
        
        pool["sim"] = sims
        cand = pool[(pool["sim"] > 0.1) & (pool["ì „ì²´ê°€ì¤‘ì¹˜"] >= weight_threshold)]
        
        if cand.empty:
            return None
        
        cand = cand.sort_values(["sim", "ì „ì²´ê°€ì¤‘ì¹˜"], ascending=False).head(20)
        
        joined = [
            f"ì œëª©: {r['ì œëª©']}\në‚´ìš©: {str(r['ì£¼ìš”ë‚´ìš©'])[:300]}"
            for _, r in cand.iterrows()
        ]
        
        prompt = f"""
        ë‹¹ì‹ ì€ í•œêµ­ ì–¸ë¡ ì‚¬ì˜ {industry if industry!='ì „ì²´' else ''} ë‹´ë‹¹ í¸ì§‘êµ­ì¥ì…ë‹ˆë‹¤.
        ì£¼ì œ: {topic}
        
        ì•„ë˜ ê¸°ì‚¬ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ
        1) í˜„ì¬ í•µì‹¬ íŠ¸ë Œë“œ 3ê°€ì§€
        2) ê° íŠ¸ë Œë“œë³„ ë§¤ì²´ ë³´ë„ íŠ¹ì§•
        3) ì•ìœ¼ë¡œ ë°œêµ´í•´ì•¼ í•  ì‹¬ì¸µ ê¸°íš ê¸°ì‚¬ 3ê±´(ì œëª©+ê°„ë‹¨ ì´ìœ )
        ì„ ê¸°ìë“¤ì—ê²Œ ì§€ì‹œí•˜ëŠ” êµ¬ì–´ì²´ ë©”ëª¨ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        
        ê¸°ì‚¬ ëª©ë¡:
        {os.linesep.join(joined[:10])}
        """
        
        return call_perplexity_api_cached(prompt, max_age_hours=6)
        
    except:
        return "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ================================
# ìƒˆë¡œìš´ AI ê¸°ëŠ¥ í•¨ìˆ˜ë“¤
# ================================
def generate_today_planning_items(df, industry="ì „ì²´"):
    """
    ìƒìœ„ ê°€ì¤‘ì¹˜ ê¸°ì‚¬ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ Perplexity APIë¥¼ í˜¸ì¶œ, 'ì˜¤ëŠ˜ì˜ ê¸°íš ì•„ì´í…œ' 3ê°œë¥¼ ì œì•ˆí•œë‹¤.
    """
    if df.empty:
        return "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    if industry != "ì „ì²´":
        df = df[df["ì—…ê³„"] == industry]
    
    # ê°€ì¤‘ì¹˜ ìƒìœ„ ê¸°ì‚¬ 20ê°œê¹Œì§€ ëŒ€ìƒ
    top_articles = (
        df.nlargest(20, "ì „ì²´ê°€ì¤‘ì¹˜") if "ì „ì²´ê°€ì¤‘ì¹˜" in df.columns else df.head(20)
    )
    
    texts = []
    for _, art in top_articles.iterrows():
        title = art.get("ì œëª©", "")
        body = art.get("ì£¼ìš”ë‚´ìš©", "")
        if pd.notna(title) and pd.notna(body):
            texts.append(f"ì œëª©: {title}\në‚´ìš©: {body}")
        elif pd.notna(title):
            texts.append(f"ì œëª©: {title}")
    
    if not texts:
        return "ë¶„ì„í•  ê¸°ì‚¬ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
    
    prompt = f"""
    ë‹¤ìŒì€ ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì…ë‹ˆë‹¤. ê¸°ìë“¤ì´ ì¶”ê°€ ì·¨ì¬í•˜ê¸° ì¢‹ì€ 'ê¸°íš ì•„ì´í…œ' 3ê±´ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
    
    ê¸°ì‚¬ ëª©ë¡:
    {os.linesep.join(texts[:15])}
    
    [ë‹µë³€ í˜•ì‹]
    1. ê¸°íš ì•„ì´í…œ ì œëª©:
    - ì·¨ì¬ í¬ì¸íŠ¸:
    - ì˜ˆìƒ ì†ŒìŠ¤:
    
    2. ê¸°íš ì•„ì´í…œ ì œëª©:
    - ì·¨ì¬ í¬ì¸íŠ¸:
    - ì˜ˆìƒ ì†ŒìŠ¤:
    
    3. ê¸°íš ì•„ì´í…œ ì œëª©:
    - ì·¨ì¬ í¬ì¸íŠ¸:
    - ì˜ˆìƒ ì†ŒìŠ¤:
    """
    
    return (
        call_perplexity_api_cached(prompt, max_age_hours=6)
        or "ê¸°íš ì•„ì´í…œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    )

def generate_monthly_weekly_insights(df, target_month=None):
    """
    ì›”ë³„Â·ì£¼ì°¨ë³„ í•µì‹¬ ë¬¸ì¥ ìƒì„±(PPLX API) â†’ dict ë°˜í™˜
    {
        'monthly_insight': str,
        'weekly_insights': {ì£¼ì°¨: str, â€¦}
    }
    """
    if df.empty:
        return {}
    
    if target_month and "ì›”" in df.columns:
        df = df[df["ì›”"] == target_month]
    
    if df.empty:
        return {}
    
    # ì›” ì „ì²´ í•µì‹¬ ë¬¸ì¥
    month_txt = " ".join(
        (
            f"{r.get('ì œëª©','')} {r.get('ì£¼ìš”ë‚´ìš©','')}"
            for _, r in df.head(50).iterrows()
        )
    )
    
    mon_prompt = f"""
    ë‹¤ìŒì€ {target_month or 'ì´ë²ˆ ë‹¬'} ì£¼ìš” ë‰´ìŠ¤ì…ë‹ˆë‹¤.
    í•µì‹¬ ì´ìŠˆë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
    
    ë‰´ìŠ¤ ë‚´ìš©:
    {month_txt}
    """
    
    monthly_insight = call_perplexity_api_cached(mon_prompt, max_age_hours=12)
    
    # ì£¼ì°¨ë³„
    weekly_insights = {}
    if "ì£¼ì°¨" in df.columns:
        for week in sorted(df["ì£¼ì°¨"].dropna().unique()):
            w_df = df[df["ì£¼ì°¨"] == week]
            week_txt = " ".join(
                (
                    f"{r.get('ì œëª©','')} {r.get('ì£¼ìš”ë‚´ìš©','')}"
                    for _, r in w_df.head(20).iterrows()
                )
            )
            
            w_prompt = f"""
            ë‹¤ìŒì€ {week} ì£¼ìš” ë‰´ìŠ¤ì…ë‹ˆë‹¤.
            í•µì‹¬ ì´ìŠˆë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
            
            ë‰´ìŠ¤ ë‚´ìš©:
            {week_txt}
            """
            
            weekly_insights[week] = call_perplexity_api_cached(
                w_prompt, max_age_hours=24
            )
    
    return {"monthly_insight": monthly_insight, "weekly_insights": weekly_insights}

def find_similar_articles_to_insight(df, insight, top_n=5):
    """
    í•µì‹¬ ë¬¸ì¥(insight) ê³¼ ìœ ì‚¬ë„ê°€ ë†’ì€ ê¸°ì‚¬ nê°œ ë°˜í™˜
    """
    if df.empty or not insight:
        return []
    
    df = df.copy()
    df["combined_text"] = df.apply(
        lambda r: f"{r.get('ì œëª©','')} {r.get('ì£¼ìš”ë‚´ìš©','')}", axis=1
    )
    df = df[df["combined_text"].str.strip() != ""]
    
    if df.empty or not (TfidfVectorizer and cosine_similarity):
        return []
    
    try:
        vec = TfidfVectorizer(max_features=1000)
        mat = vec.fit_transform(df["combined_text"].tolist() + [insight])
        sims = cosine_similarity(mat[-1:], mat[:-1]).flatten()
        
        idxs = sims.argsort()[::-1][:top_n]
        return [
            {"article": df.iloc[i], "similarity": sims[i]}
            for i in idxs if sims[i] > 0.1
        ]
    except:
        return []

# ================================
# konlpy ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ (soynlp ëŒ€ì²´)
# ================================
def extract_keywords_okt(text_list, top_n=15):
    """konlpy Oktë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    try:
        if not text_list:
            return []
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        if isinstance(text_list, str):
            text_list = [text_list]
        
        # í…ìŠ¤íŠ¸ ì •ì œ
        cleaned_texts = []
        for text in text_list:
            if pd.notna(text):
                # ê¸°ë³¸ ì •ì œ
                text = str(text).strip()
                text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
                text = re.sub(r'\s+', ' ', text)
                if len(text) > 10:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸
                    cleaned_texts.append(text)
        
        if not cleaned_texts:
            return []
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        corpus = ' '.join(cleaned_texts)
        
        # ëª…ì‚¬ ì¶”ì¶œ
        nouns = okt.nouns(corpus)
        
        # ëª…ì‚¬ ë¹ˆë„ ê³„ì‚°
        noun_freq = Counter(nouns)
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = {
            'ê¸°ì', 'ì‚¬ì§„', 'ì œê³µ', 'ê´€ë ¨', 'ì—…ê³„', 'ì‹œì¥', 'ë¶„ì•¼', 'íšŒì‚¬', 'ê¸°ì—…',
            'ë°œí‘œ', 'ê³µê°œ', 'ì„¤ëª…', 'ë³´ë„', 'ë‰´ìŠ¤', 'ê¸°ì‚¬', 'ì˜¤ëŠ˜', 'ì–´ì œ', 'ë‚´ì¼',
            'ìµœê·¼', 'í˜„ì¬', 'ë‹¹ì‹œ', 'ì´ë²ˆ', 'ë‹¤ìŒ', 'ì§€ë‚œ', 'êµ­ë‚´', 'í•´ì™¸', 'ì „êµ­',
            'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë°', 'ë˜', 'ë”', 'ì´', 'ê·¸', 'ì„', 'ë¥¼', 'ì˜', 'ê°€',
            'ë§í–ˆë‹¤', 'ë°í˜”ë‹¤', 'ì „í–ˆë‹¤', 'í–ˆë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤', 'í•œë‹¤', 'ëœë‹¤'
        }
        
        # ìµœì¢… í‚¤ì›Œë“œ ì„ ë³„
        final_keywords = []
        for word, freq in noun_freq.most_common():
            if (word not in stopwords and 
                not word.isdigit() and 
                len(word) >= 2 and len(word) <= 10 and
                re.search(r'[ê°€-í£]', word)):
                final_keywords.append((word, freq))
        
        return final_keywords[:top_n]
        
    except Exception as e:
        st.error(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        return extract_keywords_simple(text_list, top_n)

def extract_keywords_simple(text_list, top_n=10):
    """ë°±ì—…ìš© ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    try:
        if isinstance(text_list, str):
            text_list = [text_list]
        
        all_text = ' '.join([str(text) for text in text_list if pd.notna(text)])
        
        # ê°„ë‹¨í•œ í† í°í™”
        words = re.findall(r'[ê°€-í£]{2,6}', all_text)
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = {
            'ê¸°ì', 'ì‚¬ì§„', 'ì œê³µ', 'ê´€ë ¨', 'ì—…ê³„', 'ì‹œì¥', 'ë¶„ì•¼', 'íšŒì‚¬', 'ê¸°ì—…',
            'ë°œí‘œ', 'ê³µê°œ', 'ì„¤ëª…', 'ë³´ë„', 'ë‰´ìŠ¤', 'ê¸°ì‚¬', 'ì˜¤ëŠ˜', 'ì–´ì œ', 'ë‚´ì¼'
        }
        
        keywords = [word for word in words if word not in stopwords]
        word_freq = Counter(keywords)
        
        return word_freq.most_common(top_n)
    except:
        return []

# ê¸°ì¡´ extract_keywords_mecab í•¨ìˆ˜ ëŒ€ì²´
def extract_keywords_mecab(text, top_n=10):
    """í‚¤ì›Œë“œ ì¶”ì¶œ - konlpy Okt ì‚¬ìš©"""
    if isinstance(text, str):
        return extract_keywords_okt([text], top_n)
    elif isinstance(text, list):
        return extract_keywords_okt(text, top_n)
    else:
        return extract_keywords_okt([str(text)], top_n)

# ================================
# ì—…ê³„ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ ê¸°ëŠ¥
# ================================
def extract_industry_keywords(df, industry):
    """ì—…ê³„ë³„ íŠ¹í™” í‚¤ì›Œë“œ ì¶”ì¶œ"""
    if industry != 'ì „ì²´':
        industry_articles = df[df['ì—…ê³„'] == industry]
    else:
        industry_articles = df
    
    titles = industry_articles['ì œëª©'].dropna().tolist()
    
    # konlpy Oktë¡œ ì—…ê³„ íŠ¹í™” í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = extract_keywords_okt(titles, 20)
    
    # ì—…ê³„ë³„ ê°€ì¤‘ì¹˜ ì¡°ì •
    industry_weights = {
        'ìë™ì°¨': ['ì „ê¸°ì°¨', 'ììœ¨ì£¼í–‰', 'ë°°í„°ë¦¬', 'ëª¨ë¹Œë¦¬í‹°', 'ì „ë™í™”'],
        'IT/ì „ì': ['AI', 'ë°˜ë„ì²´', 'í´ë¼ìš°ë“œ', 'ë””ì§€í„¸', 'ì¸ê³µì§€ëŠ¥'],
        'ê¸ˆìœµ': ['í•€í…Œí¬', 'ê°€ìƒí™”í', 'ë¸”ë¡ì²´ì¸', 'íˆ¬ì', 'ë””ì§€í„¸ë±…í‚¹'],
        'ë°”ì´ì˜¤': ['ë°±ì‹ ', 'ì¹˜ë£Œì œ', 'ì„ìƒ', 'ì‹ ì•½', 'ì˜ë£Œ'],
        'í™”í•™/ì—ë„ˆì§€': ['ì¹œí™˜ê²½', 'íƒ„ì†Œì¤‘ë¦½', 'ì¬ìƒì—ë„ˆì§€', 'ìˆ˜ì†Œ'],
        'í•­ê³µ/ìš´ì†¡': ['ë¬¼ë¥˜', 'ë°°ì†¡', 'ëª¨ë¹Œë¦¬í‹°', 'ìš´ì†¡'],
        'ê±´ì„¤/ë¶€ë™ì‚°': ['ê°œë°œ', 'ë¶„ì–‘', 'ì¬ê±´ì¶•', 'ë¦¬ëª¨ë¸ë§'],
        'ìœ í†µ/ì†Œë¹„ì¬': ['ì´ì»¤ë¨¸ìŠ¤', 'ì˜¨ë¼ì¸', 'ë°°ì†¡', 'ì†Œë¹„'],
        'ì—”í„°í…Œì¸ë¨¼íŠ¸/ë¯¸ë””ì–´': ['ì½˜í…ì¸ ', 'í”Œë«í¼', 'ìŠ¤íŠ¸ë¦¬ë°', 'OTT'],
        'ê²Œì„': ['ë©”íƒ€ë²„ìŠ¤', 'ê²Œì„', 'í”Œë«í¼', 'ëª¨ë°”ì¼'],
        'ì‹í’ˆ/ìŒë£Œ': ['ê±´ê°•', 'í”„ë¦¬ë¯¸ì—„', 'ì¹œí™˜ê²½', 'ìœ ê¸°ë†']
    }
    
    if industry in industry_weights:
        boost_keywords = industry_weights[industry]
        enhanced_keywords = []
        for word, score in keywords:
            if any(boost in word for boost in boost_keywords):
                enhanced_keywords.append((word, score * 1.5))
            else:
                enhanced_keywords.append((word, score))
        return sorted(enhanced_keywords, key=lambda x: x[1], reverse=True)
    
    return keywords

# ================================
# ë„¤ì´ë²„ ë§í¬ í•˜ì´í¼ë§í¬ ì²˜ë¦¬ í•¨ìˆ˜ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„)
# ================================
def get_naver_link_column(df):
    """êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë„¤ì´ë²„ ë§í¬ ì»¬ëŸ¼ëª…ì„ ì°¾ëŠ” í•¨ìˆ˜"""
    possible_columns = ['ë„¤ì´ë²„ë§í¬', 'ë„¤ì´ë²„ ë§í¬', 'ë„¤ì´ë²„URL', 'ë„¤ì´ë²„ URL', 'naver_link', 'naver_url']
    for col in possible_columns:
        if col in df.columns:
            return col
    
    # ìœ ì‚¬í•œ ì»¬ëŸ¼ëª… ì°¾ê¸°
    for col in df.columns:
        if 'ë„¤ì´ë²„' in str(col) and ('ë§í¬' in str(col) or 'URL' in str(col)):
            return col
    
    return None

def get_media_link_column(df):
    """êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë§¤ì²´ë§í¬ ì»¬ëŸ¼ëª…ì„ ì°¾ëŠ” í•¨ìˆ˜"""
    possible_columns = ['ë§¤ì²´ë§í¬', 'ë§¤ì²´ ë§í¬', 'ë§¤ì²´URL', 'ë§¤ì²´ URL', 'media_link', 'media_url']
    for col in possible_columns:
        if col in df.columns:
            return col
    
    # ìœ ì‚¬í•œ ì»¬ëŸ¼ëª… ì°¾ê¸°
    for col in df.columns:
        if 'ë§¤ì²´' in str(col) and ('ë§í¬' in str(col) or 'URL' in str(col)):
            return col
    
    return None

def create_article_hyperlink(title, naver_url=None, media_url=None):
    """ê¸°ì‚¬ ì œëª©ì— í•˜ì´í¼ë§í¬ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    if pd.isna(title):
        title = "ì œëª© ì—†ìŒ"
    else:
        title = str(title).strip()
    
    # 1ìˆœìœ„: ë„¤ì´ë²„ë§í¬ ì‚¬ìš©
    if pd.notna(naver_url) and str(naver_url).strip() and str(naver_url).strip().lower() not in ['nan', '', 'none']:
        naver_url = str(naver_url).strip()
        if not naver_url.startswith(('http://', 'https://')):
            naver_url = 'https://' + naver_url
        return f'ğŸ“° [{title}]({naver_url})'
    
    # 2ìˆœìœ„: ë§¤ì²´ë§í¬ ì‚¬ìš©
    if pd.notna(media_url) and str(media_url).strip() and str(media_url).strip().lower() not in ['nan', '', 'none']:
        media_url = str(media_url).strip()
        if not media_url.startswith(('http://', 'https://')):
            media_url = 'https://' + media_url
        return f'ğŸ“° [{title}]({media_url})'
    
    return f"ğŸ“„ {title}"

def display_article_with_link(article, df=None):
    """ê¸°ì‚¬ë¥¼ í•˜ì´í¼ë§í¬ì™€ í•¨ê»˜ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
    title = article.get('ì œëª©', 'ì œëª© ì—†ìŒ')
    
    # ë„¤ì´ë²„ ë§í¬ ì»¬ëŸ¼ëª… ìë™ ê°ì§€
    if df is not None:
        naver_col = get_naver_link_column(df)
        naver_url = article.get(naver_col) if naver_col else None
        
        # ë§¤ì²´ ë§í¬ ì»¬ëŸ¼ëª… ìë™ ê°ì§€
        media_col = get_media_link_column(df)
        media_url = article.get(media_col) if media_col else None
    else:
        naver_url = article.get('ë„¤ì´ë²„ë§í¬') or article.get('ë„¤ì´ë²„ URL')
        media_url = article.get('ë§¤ì²´ë§í¬') or article.get('ë§¤ì²´ URL')
    
    # í•˜ì´í¼ë§í¬ê°€ ì ìš©ëœ ì œëª© ìƒì„±
    linked_title = create_article_hyperlink(title, naver_url, media_url)
    return linked_title

# ================================
# PyArrow ì˜¤ë¥˜ í•´ê²°ìš© ì•ˆì „í•œ í…Œì´ë¸” í‘œì‹œ í•¨ìˆ˜
# ================================
def safe_display_dataframe(df, title="ë°ì´í„°"):
    """PyArrow ì˜¤ë¥˜ë¥¼ í”¼í•œ ì•ˆì „í•œ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ"""
    try:
        # ë¨¼ì € st.dataframe ì‹œë„
        st.dataframe(df, use_container_width=True)
    except Exception as e:
        # PyArrow ì˜¤ë¥˜ ì‹œ ëŒ€ì•ˆ í‘œì‹œ
        st.warning(f"âš ï¸ í‘œ í‘œì‹œ ì˜¤ë¥˜ (PyArrow): {str(e)}")
        st.markdown(f"### ğŸ“Š {title}")
        
        # HTML í…Œì´ë¸”ë¡œ ëŒ€ì²´
        html_table = "<table style='width:100%; border-collapse: collapse;'>"
        html_table += "<tr style='background-color: #f0f0f0;'>"
        for col in df.columns:
            html_table += f"<th style='border: 1px solid #ddd; padding: 8px;'>{col}</th>"
        html_table += "</tr>"
        
        for _, row in df.head(10).iterrows():
            html_table += "<tr>"
            for col in df.columns:
                html_table += f"<td style='border: 1px solid #ddd; padding: 8px;'>{row[col]}</td>"
            html_table += "</tr>"
        
        html_table += "</table>"
        st.markdown(html_table, unsafe_allow_html=True)
        
        st.markdown(f"*... ì´ {len(df)}ê°œ í–‰ ì¤‘ 10ê°œë§Œ í‘œì‹œ*")

# ================================
# ë¡œê·¸ì¸ í•¨ìˆ˜
# ================================
def check_password():
    """ê¸°ììš© ë¡œê·¸ì¸ í™”ë©´"""
    if st.session_state.get('authenticated', False):
        return True
    
    st.markdown("""
    <div style='text-align: center; padding: 2rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                border-radius: 20px; margin-bottom: 2rem; color: white;'>
        <h2>ğŸ” ê¸°ìë‹˜ë“¤ì„ ìœ„í•œ ì „ìš© ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤</h2>
        <p>AI ê¸°ë°˜ ê¸°ì‚¬ ë¶„ì„ í”Œë«í¼</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ë¡œê·¸ì¸ í¼
    with st.form("login_form"):
        password = st.text_input("ğŸ”‘ ì ‘ì† ë¹„ë°€ë²ˆí˜¸", type="password")
        submitted = st.form_submit_button("ë¡œê·¸ì¸", use_container_width=True)
        
        if submitted:
            if password == APP_PASSWORD:
                st.session_state.authenticated = True
                st.success("âœ… ë¡œê·¸ì¸ ì„±ê³µ! ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
                time.sleep(1)
                st.rerun()
            else:
                st.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    return False

# ================================
# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§
# ================================
def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ í•¨ìˆ˜"""
    
    # ë¡œê·¸ì¸ í™•ì¸
    if not check_password():
        st.stop()
    
    # ë©”ì¸ í—¤ë”
    st.markdown("""
    <div style='text-align: center; padding: 2rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                border-radius: 20px; margin-bottom: 2rem; color: white;'>
        <h1>ğŸš€ ë‰´ìŠ¤íŒ©í† ë¦¬ AI ê¸°ë°˜ ê¸°ì‚¬ ë¶„ì„ í”Œë«í¼</h1>
        <p>konlpy ê¸°ë°˜ í•œêµ­ì–´ ì²˜ë¦¬ ì‹œìŠ¤í…œ</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ì—°ê²° ìƒíƒœ í™•ì¸
    if SHEETS_UTILS_AVAILABLE:
        status = get_connection_status()
        if status['connected']:
            st.success("âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„±ê³µ")
        else:
            st.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {status['message']}")
            st.stop()
    else:
        st.error("âŒ êµ¬ê¸€ ì‹œíŠ¸ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # ë°ì´í„° ë¡œë“œ
    with st.spinner("ğŸ”„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        df = load_data_from_google_sheets()
        
        if df.empty:
            st.error("âŒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
        
        # ì „ì²˜ë¦¬
        df = preprocess_dataframe(df)
        
        if df.empty:
            st.error("âŒ ë°ì´í„° ì „ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            st.stop()
    
    st.success(f"âœ… ì´ {len(df)}ê°œ ê¸°ì‚¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    
    # ì‚¬ì´ë“œë°” - ì—…ê³„ ì„ íƒ
    st.sidebar.header("ğŸ” í•„í„° ì„¤ì •")
    
    industries = ["ì „ì²´"] + sorted(df["ì—…ê³„"].dropna().unique().tolist())
    selected_industry = st.sidebar.selectbox("ì—…ê³„ ì„ íƒ", industries)
    
    # í•„í„°ëœ ë°ì´í„°
    filtered_df = df if selected_industry == "ì „ì²´" else df[df["ì—…ê³„"] == selected_industry]
    
    # ë©”ì¸ íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ë°ì´í„° ë¶„ì„", "ğŸ” í‚¤ì›Œë“œ ë¶„ì„", "ğŸ¤– AI ì¸ì‚¬ì´íŠ¸", "ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„"])
    
    with tab1:
        st.header("ğŸ“Š ê¸°ì‚¬ ë°ì´í„° ë¶„ì„")
        
        # ê¸°ë³¸ í†µê³„
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì´ ê¸°ì‚¬ ìˆ˜", len(filtered_df))
        
        with col2:
            if "ì „ì²´ê°€ì¤‘ì¹˜" in filtered_df.columns:
                avg_weight = filtered_df["ì „ì²´ê°€ì¤‘ì¹˜"].mean()
                st.metric("í‰ê·  ê°€ì¤‘ì¹˜", f"{avg_weight:.3f}")
            else:
                st.metric("í‰ê·  ê°€ì¤‘ì¹˜", "ë¯¸ê³„ì‚°")
        
        with col3:
            if "ì›”" in filtered_df.columns:
                month_count = filtered_df["ì›”"].nunique()
                st.metric("ëŒ€ìƒ ì›”", f"{month_count}ê°œì›”")
            else:
                st.metric("ëŒ€ìƒ ì›”", "ë¯¸ë¶„ë¥˜")
        
        with col4:
            if "ì—…ê³„" in filtered_df.columns:
                industry_count = filtered_df["ì—…ê³„"].nunique()
                st.metric("ì—…ê³„ ìˆ˜", f"{industry_count}ê°œ")
            else:
                st.metric("ì—…ê³„ ìˆ˜", "ë¯¸ë¶„ë¥˜")
        
        # ìƒìœ„ ê¸°ì‚¬ í‘œì‹œ
        st.subheader("ğŸ† ìƒìœ„ ê°€ì¤‘ì¹˜ ê¸°ì‚¬")
        
        if "ì „ì²´ê°€ì¤‘ì¹˜" in filtered_df.columns:
            top_articles = filtered_df.nlargest(10, "ì „ì²´ê°€ì¤‘ì¹˜")
        else:
            top_articles = filtered_df.head(10)
        
        for idx, (_, article) in enumerate(top_articles.iterrows(), 1):
            with st.expander(f"{idx}. {article.get('ì œëª©', 'ì œëª© ì—†ìŒ')}"):
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    st.write(f"**ë§¤ì²´**: {article.get('ë§¤ì²´', 'ì •ë³´ ì—†ìŒ')}")
                    st.write(f"**ë‚ ì§œ**: {article.get('ë³´ë„ë‚ ì§œ', 'ì •ë³´ ì—†ìŒ')}")
                    st.write(f"**ì—…ê³„**: {article.get('ì—…ê³„', 'ì •ë³´ ì—†ìŒ')}")
                    if pd.notna(article.get('ì£¼ìš”ë‚´ìš©')):
                        st.write(f"**ë‚´ìš©**: {str(article.get('ì£¼ìš”ë‚´ìš©'))[:200]}...")
                
                with col2:
                    if "ì „ì²´ê°€ì¤‘ì¹˜" in article:
                        st.metric("ê°€ì¤‘ì¹˜", f"{article['ì „ì²´ê°€ì¤‘ì¹˜']:.3f}")
                    
                    # ë§í¬ í‘œì‹œ
                    linked_title = display_article_with_link(article, df)
                    st.markdown(linked_title)
    
    with tab2:
        st.header("ğŸ” í‚¤ì›Œë“œ ë¶„ì„")
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        st.subheader("ğŸ“ ì£¼ìš” í‚¤ì›Œë“œ")
        
        with st.spinner("ğŸ”„ í‚¤ì›Œë“œ ë¶„ì„ ì¤‘..."):
            # ì œëª© ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
            titles = filtered_df["ì œëª©"].dropna().tolist()
            keywords = extract_keywords_okt(titles, 20)
            
            if keywords:
                # í‚¤ì›Œë“œ í…Œì´ë¸”
                keyword_df = pd.DataFrame(keywords, columns=["í‚¤ì›Œë“œ", "ë¹ˆë„"])
                
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.dataframe(keyword_df, use_container_width=True)
                
                with col2:
                    # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ì°¨íŠ¸
                    if len(keywords) >= 10:
                        chart_data = pd.DataFrame(keywords[:10], columns=["í‚¤ì›Œë“œ", "ë¹ˆë„"])
                        st.bar_chart(chart_data.set_index("í‚¤ì›Œë“œ"))
            else:
                st.warning("âš ï¸ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì—…ê³„ë³„ í‚¤ì›Œë“œ
        if selected_industry != "ì „ì²´":
            st.subheader(f"ğŸ¢ {selected_industry} ì—…ê³„ íŠ¹í™” í‚¤ì›Œë“œ")
            
            industry_keywords = extract_industry_keywords(df, selected_industry)
            
            if industry_keywords:
                industry_keyword_df = pd.DataFrame(industry_keywords[:15], columns=["í‚¤ì›Œë“œ", "ê°€ì¤‘ì ìˆ˜"])
                st.dataframe(industry_keyword_df, use_container_width=True)
    
    with tab3:
        st.header("ğŸ¤– AI ì¸ì‚¬ì´íŠ¸")
        
        # ì˜¤ëŠ˜ì˜ ê¸°íš ì•„ì´í…œ
        st.subheader("ğŸ’¡ ì˜¤ëŠ˜ì˜ ê¸°íš ì•„ì´í…œ")
        
        if st.button("ğŸš€ AI ê¸°íš ì•„ì´í…œ ìƒì„±", use_container_width=True):
            with st.spinner("ğŸ¤– AIê°€ ê¸°íš ì•„ì´í…œì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                planning_items = generate_today_planning_items(filtered_df, selected_industry)
                
                st.markdown(f"""
                <div class="insight-box">
                    <h3>ğŸ’¡ AI ì¶”ì²œ ê¸°íš ì•„ì´í…œ</h3>
                    <p>{planning_items}</p>
                </div>
                """, unsafe_allow_html=True)
        
        # ì›”ë³„/ì£¼ì°¨ë³„ ì¸ì‚¬ì´íŠ¸
        st.subheader("ğŸ“… ì›”ë³„/ì£¼ì°¨ë³„ ì¸ì‚¬ì´íŠ¸")
        
        if "ì›”" in filtered_df.columns:
            available_months = sorted(filtered_df["ì›”"].dropna().unique())
            if available_months:
                selected_month = st.selectbox("ë¶„ì„í•  ì›” ì„ íƒ", available_months)
                
                if st.button("ğŸ” ì›”ë³„ ì¸ì‚¬ì´íŠ¸ ìƒì„±", use_container_width=True):
                    with st.spinner("ğŸ¤– AIê°€ ì›”ë³„ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                        insights = generate_monthly_weekly_insights(filtered_df, selected_month)
                        
                        if insights.get("monthly_insight"):
                            st.markdown(f"""
                            <div class="insight-box">
                                <h3>ğŸ“Š {selected_month} ì›”ë³„ í•µì‹¬ ì¸ì‚¬ì´íŠ¸</h3>
                                <p>{insights['monthly_insight']}</p>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        if insights.get("weekly_insights"):
                            st.subheader("ğŸ“… ì£¼ì°¨ë³„ ì¸ì‚¬ì´íŠ¸")
                            for week, insight in insights["weekly_insights"].items():
                                if insight:
                                    st.markdown(f"""
                                    <div class="planning-item">
                                        <strong>{week}:</strong> {insight}
                                    </div>
                                    """, unsafe_allow_html=True)
        
        # ì»¤ìŠ¤í…€ ì£¼ì œ ë¸Œë¦¬í•‘
        st.subheader("ğŸ¯ ì»¤ìŠ¤í…€ ì£¼ì œ ë¸Œë¦¬í•‘")
        
        custom_topic = st.text_input("ë¶„ì„í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì „ê¸°ì°¨ ì‹œì¥ ë™í–¥")
        
        if st.button("ğŸ” ì£¼ì œ ë¸Œë¦¬í•‘ ìƒì„±", use_container_width=True) and custom_topic:
            with st.spinner("ğŸ¤– AIê°€ ì£¼ì œ ë¸Œë¦¬í•‘ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                topic_brief = generate_custom_topic_brief(filtered_df, selected_industry, custom_topic)
                
                if topic_brief:
                    st.markdown(f"""
                    <div class="insight-box">
                        <h3>ğŸ¯ {custom_topic} ë¸Œë¦¬í•‘</h3>
                        <p>{topic_brief}</p>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.warning("âš ï¸ í•´ë‹¹ ì£¼ì œì— ëŒ€í•œ ê´€ë ¨ ê¸°ì‚¬ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    with tab4:
        st.header("ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„")
        
        # ì›”ë³„ ê¸°ì‚¬ ìˆ˜ ì¶”ì´
        if "ì›”" in filtered_df.columns:
            st.subheader("ğŸ“Š ì›”ë³„ ê¸°ì‚¬ ìˆ˜ ì¶”ì´")
            
            monthly_counts = filtered_df["ì›”"].value_counts().sort_index()
            st.bar_chart(monthly_counts)
        
        # ì—…ê³„ë³„ ë¶„í¬
        if "ì—…ê³„" in filtered_df.columns:
            st.subheader("ğŸ¢ ì—…ê³„ë³„ ê¸°ì‚¬ ë¶„í¬")
            
            industry_counts = filtered_df["ì—…ê³„"].value_counts().head(10)
            st.bar_chart(industry_counts)
        
        # ë§¤ì²´ë³„ ë¶„í¬
        if "ë§¤ì²´" in filtered_df.columns:
            st.subheader("ğŸ“° ë§¤ì²´ë³„ ê¸°ì‚¬ ë¶„í¬")
            
            media_counts = filtered_df["ë§¤ì²´"].value_counts().head(10)
            st.bar_chart(media_counts)
        
        # ê°€ì¤‘ì¹˜ ë¶„í¬
        if "ì „ì²´ê°€ì¤‘ì¹˜" in filtered_df.columns:
            st.subheader("âš–ï¸ ê°€ì¤‘ì¹˜ ë¶„í¬")
            
            st.histogram(filtered_df["ì „ì²´ê°€ì¤‘ì¹˜"], bins=20)
    
    # í‘¸í„°
    st.markdown("""
    <div style='text-align: center; padding: 1rem; margin-top: 2rem; 
                background: rgba(255,255,255,0.1); border-radius: 10px;'>
        <p>ğŸš€ ë‰´ìŠ¤íŒ©í† ë¦¬ AI ê¸°ë°˜ ê¸°ì‚¬ ë¶„ì„ í”Œë«í¼ (konlpy ë²„ì „)</p>
        <p>âœ¨ ì „ë¬¸ ê¸°ìë¥¼ ìœ„í•œ AI ë‰´ìŠ¤ ë¶„ì„ ë„êµ¬</p>
    </div>
    """, unsafe_allow_html=True)

# ================================
# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
# ================================
if __name__ == "__main__":
    main()
